{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a55463a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85963213",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==================================================================================\n",
    "#       Copyright (c) 2020 China Mobile Technology (USA) Inc. Intellectual Property.\n",
    "#\n",
    "#   Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#   you may not use this file except in compliance with the License.\n",
    "#   You may obtain a copy of the License at\n",
    "#\n",
    "#          http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#   Unless required by applicable law or agreed to in writing, software\n",
    "#   distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#   See the License for the specific language governing permissions and\n",
    "#   limitations under the License.\n",
    "# ==================================================================================\n",
    "\"\"\"\n",
    "lp entrypoint module\n",
    "\n",
    "RMR Messages\n",
    " #define TS_UE_LIST 30000\n",
    "for now re-use the 30000 to receive a UEID for prediction\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('C:/Users/Mohammadreza/Desktop/My Class/Proj-DC/My Works/Scheduling/xApp/mr7-main')\n",
    "import schedule\n",
    "from zipfile import ZipFile\n",
    "import json\n",
    "from os import getenv\n",
    "#from ricxappframe.xapp_frame import RMRXapp, rmr, Xapp\n",
    "from mr_2 import sdl\n",
    "#from lp.exceptions import UENotFound, CellNotFound\n",
    "\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from numpy import zeros, newaxis\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "from mr_2.db import DATABASE, DUMMY\n",
    "import mr_2.populate as populate\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import gym\n",
    "import mobile_env\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statistics\n",
    "from statistics import mean\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython\n",
    "from IPython import display\n",
    "from mobile_env.handlers.central import MComCentralHandler\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cebc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential  # To compose multiple Layers\n",
    "from tensorflow.keras.layers import LSTM, Dense  # Fully-Connected layer\n",
    "from tensorflow.keras.layers import Activation  # Activation functions\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23e27c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mobile_env.core.base import MComCore\n",
    "from mobile_env.core.entities import BaseStation, UserEquipment\n",
    "\n",
    "# predefined small scenarios\n",
    "from mobile_env.scenarios.small import MComSmall\n",
    "\n",
    "\n",
    "# easy access to the default configuration\n",
    "MComSmall.default_config()\n",
    "\n",
    "env = gym.make(\"mobile-small-central-v0\")\n",
    "\n",
    "num_states = 7\n",
    "print(\"Size of State Space ->  {}\".format(num_states))\n",
    "num_whole_states = 35\n",
    "print(\"Size of Whole State Space ->  {}\".format(num_whole_states))\n",
    "num_actions = 4\n",
    "print(\"Size of Action Space ->  {}\".format(num_actions))\n",
    "num_ues = 5\n",
    "upper_bound = env.NUM_STATIONS\n",
    "lower_bound = 0\n",
    "print(\"Max Value of Action ->  {}\".format(upper_bound))\n",
    "print(\"Min Value of Action ->  {}\".format(lower_bound))\n",
    "# Configuration parameters for the whole setup\n",
    "gamma = 0.99  # Discount factor for past rewards\n",
    "max_steps_per_episode = 50\n",
    "eps = np.finfo(np.float32).eps.item()  # Smallest number such that 1.0 + eps != 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd3e0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_inputs = 4\n",
    "# num_actions = 2\n",
    "num_hidden1 = 64\n",
    "num_hidden2 = 128\n",
    "\n",
    "inputs = layers.Input(shape=(num_states,))\n",
    "common1 = layers.Dense(num_hidden1, activation=\"relu\")(inputs)\n",
    "common2 = layers.Dense(num_hidden2, activation=\"relu\")(common1)\n",
    "action = layers.Dense(num_actions, activation=\"softmax\")(common2)\n",
    "critic = layers.Dense(1, activation=\"linear\")(common2)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=[action, critic])\n",
    "\n",
    "print('model.summary in get_actor',model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14580b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "xapp = None\n",
    "print('first line of code: xapp=None=', xapp)\n",
    "pos = 0\n",
    "cell_data = None\n",
    "rmr_xapp = None\n",
    "ai_model = None\n",
    "\n",
    "class UENotFound(BaseException):\n",
    "    pass\n",
    "class CellNotFound(BaseException):\n",
    "    pass\n",
    "\n",
    "def post_init(self):\n",
    "    print('///////enter def post_init__/////////////////')\n",
    "    \"\"\"\n",
    "    Function that runs when xapp initialization is complete\n",
    "    \"\"\"\n",
    "    self.def_hand_called = 0\n",
    "    self.traffic_steering_requests = 0\n",
    "\n",
    "\n",
    "def handle_config_change(self, config):\n",
    "    print('////////enter def handle_config_change//////////////')\n",
    "    \"\"\"\n",
    "    Function that runs at start and on every configuration file change.\n",
    "    \"\"\"\n",
    "    self.logger.debug(\"handle_config_change: config: {}\".format(config))\n",
    "\n",
    "\n",
    "def default_handler(self, summary, sbuf):\n",
    "    print('/////////enter def default_handler///////////////')\n",
    "    \"\"\"\n",
    "    Function that processes messages for which no handler is defined\n",
    "    \"\"\"\n",
    "    self.def_hand_called += 1\n",
    "    print('self.def_hand_called += 1=', self.def_hand_called)\n",
    "    self.logger.warning(\"default_handler unexpected message type {}\".format(summary[rmr.RMR_MS_MSG_TYPE]))\n",
    "    self.rmr_free(sbuf)\n",
    "\n",
    "\n",
    "def mr_req_handler(self, summary, sbuf):\n",
    "    print('///////////enter def mr_req handler/////////////')\n",
    "    \"\"\"\n",
    "    This is the main handler for this xapp, which handles load prediction requests.\n",
    "    This app fetches a set of data from SDL, and calls the predict method to perform\n",
    "    prediction based on the data\n",
    "\n",
    "    The incoming message that this function handles looks like:\n",
    "        {\"UEPredictionSet\" : [\"UEId1\",\"UEId2\",\"UEId3\"]}\n",
    "    \"\"\"\n",
    "    self.traffic_steering_requests += 1\n",
    "    # we don't use rts here; free the buffer\n",
    "    self.rmr_free(sbuf)\n",
    "\n",
    "    ue_list = []\n",
    "    try:\n",
    "        print('////enter first try in mr_req_handler////')\n",
    "        print('rmr.RMR_MS_PAYLOAD=', rmr.RMR_MS_PAYLOAD)\n",
    "        print('summary[rmr.RMR_MS_PAYLOAD]=', summary[rmr.RMR_MS_PAYLOAD])\n",
    "        req = json.loads(summary[rmr.RMR_MS_PAYLOAD])  # input should be a json encoded as bytes\n",
    "        print('req = json.loads(summary[rmr.RMR_MS_PAYLOAD])=', req)\n",
    "        ue_list = req[\"UEPredictionSet\"]\n",
    "        print('ue_list=req[\"UEPredictionSet\"] =', ue_list)\n",
    "        self.logger.debug(\"mr_req_handler processing request for UE list {}\".format(ue_list))\n",
    "    except (json.decoder.JSONDecodeError, KeyError):\n",
    "        print('////enter first except in mr_req_handler////')\n",
    "        self.logger.warning(\"mr_req_handler failed to parse request: {}\".format(summary[rmr.RMR_MS_PAYLOAD]))\n",
    "        return\n",
    "    print('ue_list mr_req_handler aftr 1st try=', ue_list)\n",
    "    # iterate over the UEs, fetches data for each UE and perform prediction\n",
    "    for ueid in ue_list:\n",
    "        try:\n",
    "            print('////enter second try in mr_req_handler////')\n",
    "            uedata = sdl.get_uedata(self, ueid)\n",
    "            print('uedata = sdl.get_uedata(self, ueid)=', uedata)\n",
    "            predict(self, uedata)\n",
    "            print('predict(self, uedata)=', predict(self, uedata))\n",
    "        except UENotFound:\n",
    "            print('////enter second except in mr_req_handler////')\n",
    "            print('enter UENotFound in mr_req_handler')\n",
    "            self.logger.warning(\"mr_req_handler received a TS Request for a UE that does not exist!\")\n",
    "\n",
    "def entry():\n",
    "    print('////////////enter def entry///////////////')\n",
    "    \"\"\"  Read from DB in an infinite loop and run prediction every second\n",
    "      TODO: do training as needed in the future\n",
    "    \"\"\"\n",
    "    schedule.every(1).seconds.do(RL)\n",
    "    print('/////////pass 1 entry schedule.every(1).seconds.do(run_prediction, self)/////')\n",
    "    while True:\n",
    "        #print('////while True in entry/////') \n",
    "        schedule.run_pending()\n",
    "\n",
    "        \n",
    "        \n",
    "def RL():\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "    huber_loss = keras.losses.Huber()\n",
    "    action_probs_history = []\n",
    "    actions_probs_history = []\n",
    "    action_probs_history_test = []\n",
    "    critic_value_history = []\n",
    "    critic_value_history_test = []\n",
    "    rewards_history = []\n",
    "    reward_history_for_plot = []\n",
    "    running_rewards_history = []\n",
    "    episode_reward_history = []\n",
    "    running_reward = 0\n",
    "    episode_count = 0\n",
    "    iteration = 0\n",
    "    utility_history = []\n",
    "    episode_utility = 0\n",
    "    episode_utility_history = []\n",
    "    mean_utility_history = []\n",
    "    actor_loss_history = []\n",
    "    critic_loss_history = []\n",
    "    critic_loss_history_test = []\n",
    "    loss_value_history_whole = []\n",
    "\n",
    "    while True:  # Run until solved\n",
    "        state = env.reset()\n",
    "        print('tensor state in while True=', state)\n",
    "        episode_reward = 0\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            for timestep in range(1, max_steps_per_episode):\n",
    "                print('timestep=', timestep)\n",
    "                # env.render(); Adding this line would show the attempts\n",
    "                # of the agent in a pop up window.\n",
    "                prev_state = state\n",
    "                #print('prev_state in main=', prev_state)\n",
    "\n",
    "                state_per_user = [0]*num_states\n",
    "                #state_per_user = []\n",
    "\n",
    "                for index in range (num_ues):\n",
    "\n",
    "                    state_per_user[index] = state[(index*num_states):((index*num_states)+num_states)]\n",
    "                    #state_per_user.append(state[(index*num_states):((index*num_states)+num_states)])\n",
    "                    #print('state_per_user[index]=', state_per_user[index])\n",
    "\n",
    "\n",
    "                state_all_users = []\n",
    "                for i in range (num_ues):\n",
    "                    state_all_users.append(state_per_user[:][i])\n",
    "                #print('state_all_users=', state_all_users)\n",
    "                state_all_users = tf.convert_to_tensor(state_all_users)    \n",
    "                #print('tf.convert_to_tensor(state_all_users)=', state_all_users)\n",
    "\n",
    "                action_probs, critic_value = model(state_all_users)\n",
    "                #print('action_probs=', action_probs)\n",
    "                #print('critic_value=', critic_value)\n",
    "                #print('critic_value[:, 0]=', critic_value[:, 0])\n",
    "                critic_value_history.append(critic_value[:, 0])\n",
    "                #print('critic_value_history.append(critic_value[0, 0])', critic_value_history)\n",
    "                critic_value_history_test.append(critic_value)\n",
    "                #print('critic_value_history_test.append(critic_value)=', critic_value_history_test)\n",
    "\n",
    "\n",
    "\n",
    "                # Sample action from action probability distribution\n",
    "                #print('paaaaaaaaaaasssseeeddddddddddd shittttttttttttttt')\n",
    "                actions = [0]*num_ues\n",
    "                action_probs_per_action = []\n",
    "                p_whole = []\n",
    "                for i in range(num_ues):\n",
    "                    #print('i=', i)\n",
    "                    #print('action_probs[i]=', action_probs[i])\n",
    "                    #print('action_probs[i,:]=', action_probs[i,:])\n",
    "                    #print('p=np.squeeze(action_probs[i,:])=', np.squeeze(action_probs[i,:]))\n",
    "                    #print('tf.squeeze(action_probs[i,:])=', tf.squeeze(action_probs[i,:]))\n",
    "                    action = np.random.choice(num_actions, p=np.squeeze(action_probs[i]))\n",
    "\n",
    "                    #print('action=', action)\n",
    "                    actions[i]=action\n",
    "                    #print('actions=', actions)\n",
    "                    action_probs_per_action.append(action_probs[i, action])\n",
    "                    #print('action_probs_per_action.append(action_probs[i, action])=', action_probs_per_action)\n",
    "\n",
    "                    #print('tf.math.log(action_probs[i, action])=', tf.math.log(action_probs[i, action]))\n",
    "                    action_probs_history.append(tf.math.log(action_probs[i, action]))\n",
    "                    #print('action_probs_history.append(tf.math.log(action_probs[i, action]))=', action_probs_history)\n",
    "\n",
    "                #print('tf.math.log(action_probs_per_action)=', tf.math.log(action_probs_per_action))\n",
    "                action_probs_history_test.append(tf.math.log(action_probs_per_action))\n",
    "                #print('action_probs_history_test.append(tf.math.log(action_probs_per_action))=',action_probs_history_test)\n",
    "                actions_probs_history.append(action_probs_history)\n",
    "                #print('actions_probs_history=', actions_probs_history)\n",
    "                actions_tensor = tf.convert_to_tensor(actions) \n",
    "                print('actions_tensor=', actions_tensor)\n",
    "                actions = np.asarray(actions, dtype=np.int64)\n",
    "                #print('actions_a_array=', actions_a)\n",
    "\n",
    "\n",
    "                # Apply the sampled action in our environment\n",
    "                \n",
    "                state, reward, done = connectdb(actions)\n",
    "                #state, reward, done, info = env.step(actions)\n",
    "                #network_reward = self.utilities_scaled_float_mean\n",
    "                #print('state=state, reward, done = connectdb(actions)=', state)\n",
    "                state = np.array(state, dtype='float32')\n",
    "                #print('state = np.array(state)=', state)\n",
    "                print('reward:connectdb(actions)=', reward)\n",
    "                #print('network_reward=', network_reward)\n",
    "                print('done=env.step(actions)=', done)\n",
    "                #print('info=env.step(actions)=', info)\n",
    "                #print('utility=env.step(actions)=', utility)\n",
    "                rewards_history.append(reward)\n",
    "                reward_history_for_plot.append(reward)\n",
    "                #utility_history.append(utility)\n",
    "                #print('rewards_history.append(reward)=', rewards_history)\n",
    "                episode_reward += reward\n",
    "                #print('episode_reward += reward=', episode_reward)\n",
    "                episode_reward_history.append(episode_reward)\n",
    "                #episode_utility +=utility\n",
    "                #episode_utility_history.append(episode_utility)\n",
    "\n",
    "\n",
    "                if done:\n",
    "\n",
    "                    break\n",
    "\n",
    "            iteration +=1\n",
    "            # load all tracked results as pandas data frames\n",
    "            scalar_results_1 = env.monitor.load_results()\n",
    "\n",
    "            # show general specific results\n",
    "            #scalar_results_1.head()\n",
    "\n",
    "            mean_utility_history.append(scalar_results_1['mean utility'].tolist())\n",
    "\n",
    "            # Update running reward to check condition for solving\n",
    "\n",
    "            running_reward = 0.05 * episode_reward + (1 - 0.05) * running_reward\n",
    "            #print('running_reward = 0.05 * epi=', running_reward)\n",
    "            running_rewards_history.append(running_reward)\n",
    "            # Calculate expected value from rewards\n",
    "            # - At each timestep what was the total reward received after that timestep\n",
    "            # - Rewards in the past are discounted by multiplying them with gamma\n",
    "            # - These are the labels for our critic\n",
    "            returns = []\n",
    "            discounted_sum = 0\n",
    "            for r in rewards_history[::-1]:\n",
    "                discounted_sum = r + gamma * discounted_sum\n",
    "                returns.insert(0, discounted_sum)\n",
    "            #print('returns=', returns)\n",
    "\n",
    "            # Normalize\n",
    "            returns = np.array(returns)\n",
    "            returns = (returns - np.mean(returns)) / (np.std(returns) + eps)\n",
    "            #print('returns=(returns - np.mean(returns)) / (np.st', returns)\n",
    "            returns = returns.tolist()\n",
    "            #print('returns.tolist()=', returns)\n",
    "\n",
    "            # Calculating loss values to update our network\n",
    "            history = zip(action_probs_history_test, critic_value_history, returns, critic_value_history_test)\n",
    "            #print('history = zip(action_probs_history, critic_value_history, returns)=', history)\n",
    "            actor_losses = []\n",
    "            critic_losses = []\n",
    "            critic_losses_test = []\n",
    "            for log_prob, value, ret, value_test in history:\n",
    "\n",
    "                # At this point in history, the critic estimated that we would get a\n",
    "                # total reward = `value` in the future. We took an action with log probability\n",
    "                # of `log_prob` and ended up recieving a total reward = `ret`.\n",
    "                # The actor must be updated so that it predicts an action that leads to\n",
    "                # high rewards (compared to critic's estimate) with high probability.\n",
    "\n",
    "                #print('log_prob=', log_prob)\n",
    "                #print('value=', value)\n",
    "                #print('ret=', ret)\n",
    "                diff = ret - value\n",
    "                #print('diff in for loop of history=', diff)\n",
    "\n",
    "                #print('diff.mul(log_prob)=', tf.multiply(-log_prob,diff))\n",
    "                #print('-log_prob * diff=', -log_prob*diff)\n",
    "                actor_losses.append(-log_prob*diff)  # actor loss\n",
    "                #actor_losses.append(tf.multiply(-log_prob,diff))  # actor loss\n",
    "                actor_loss_history.append(actor_losses)\n",
    "                #print('actor_losses.append(-log_prob * diff)=', actor_losses)\n",
    "\n",
    "                # The critic must be updated so that it predicts a better estimate of\n",
    "                # the future rewards.\n",
    "                #print('tf.expand_dims(value, 0)=', tf.expand_dims(value, 0))\n",
    "                #print('tf.expand_dims(ret, 0)=', tf.expand_dims(ret, 0))\n",
    "                #print('huber_loss(tf.expand_dims(value, 0), tf.expand_dims(ret, 0))=', huber_loss(tf.expand_dims(value, 0), tf.expand_dims(ret, 0)))\n",
    "\n",
    "                #print('value_test=', value_test)\n",
    "                #print('tf.expand_dims(value_test, 0)=', tf.expand_dims(value, 0))\n",
    "                #print('huber_loss(tf.expand_dims(value_test, 0), tf.expand_dims(ret, 0))=', huber_loss(value_test, tf.expand_dims(ret, 0)))\n",
    "                critic_losses.append(\n",
    "                    huber_loss(tf.expand_dims(value, 0), tf.expand_dims(ret, 0))\n",
    "                )\n",
    "                critic_loss_history.append(critic_losses)\n",
    "                #print('critic_losses=', critic_losses)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # Backpropagation\n",
    "            loss_value_history = []\n",
    "            grads_history = []\n",
    "            #print('actor_losses=', actor_losses)\n",
    "            #print('critic_losses=', critic_losses)\n",
    "            #print('sum(actor_losses)=', sum(actor_losses))\n",
    "            #print('sum(critic_losses)=', sum(critic_losses))\n",
    "            loss_value = sum(actor_losses) + sum(critic_losses)\n",
    "            #print('loss_value = sum(actor_losses) + sum(critic_losses)=', loss_value)\n",
    "            loss_value_history.append(loss_value)\n",
    "            loss_value_history_whole.append(loss_value)\n",
    "            #print('loss_value for backprpagation=', loss_value)\n",
    "            grads = tape.gradient(loss_value, model.trainable_variables)\n",
    "            #print('grads = tape.gradient(loss_value, model.trainable_variables)=', grads)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "            grads_history.append(grads)       \n",
    "            #print('iteration=', iteration)\n",
    "\n",
    "            # Clear the loss and reward history\n",
    "            action_probs_history.clear()\n",
    "            critic_value_history.clear()\n",
    "            rewards_history.clear()\n",
    "\n",
    "        # Log details\n",
    "        episode_count += 1\n",
    "        print('episode_count += 1=', episode_count)\n",
    "        if episode_count % 10 == 0:\n",
    "            template = \"running reward: {:.2f} at episode {}\"\n",
    "            print(template.format(running_reward, episode_count))\n",
    "\n",
    "        scalar_results_2 = env.monitor.load_results()\n",
    "    #     if scalar_results_2['mean datarate'].mean() > 20 and scalar_results_2['mean datarate'].max() < 130:\n",
    "\n",
    "\n",
    "\n",
    "        if episode_count > 1:  # Condition to consider the task solved\n",
    "            print(\"Solved at episode {}!\".format(episode_count))\n",
    "\n",
    "            scalar_results_2 = env.monitor.load_results()\n",
    "\n",
    "            plt.plot(reward_history_for_plot)\n",
    "            plt.xlabel(\"episode_count\")\n",
    "            plt.ylabel(\"reward_history_for_plot\")\n",
    "            plt.show()    \n",
    "\n",
    "            plt.plot(running_rewards_history)\n",
    "            plt.xlabel(\"episode_count\")\n",
    "            plt.ylabel(\"running_rewards_history\")\n",
    "            plt.show()\n",
    "\n",
    "            plt.plot(episode_reward_history)\n",
    "            plt.xlabel(\"episode_count\")\n",
    "            plt.ylabel(\"episode_reward\")\n",
    "            plt.show()\n",
    "\n",
    "            plt.plot(loss_value_history)\n",
    "            plt.xlabel(\"iteration\")\n",
    "            plt.ylabel(\"loss_value_history\")\n",
    "            plt.show()\n",
    "\n",
    "            plt.plot(utility_history)\n",
    "            plt.xlabel(\"episode_count\")\n",
    "            plt.ylabel(\"utility_history\")\n",
    "            plt.show()\n",
    "\n",
    "            plt.plot(episode_utility_history)\n",
    "            plt.xlabel(\"episode_count\")\n",
    "            plt.ylabel(\"episode_utility_history\")\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "            break\n",
    "\n",
    "        \n",
    "def run_prediction():\n",
    "    print('///////////////enter def run_prediction///////////////')\n",
    "    \"\"\"Read the latest cell_meas sample from influxDB and run it by the model inference\n",
    "    \"\"\"\n",
    "\n",
    "    global pos\n",
    "    sample = [3735, 0, 27648, 2295, 18, -1, 16383,-1, -1, -1]\n",
    "    print('sample=[3735,...]=', sample)\n",
    "    if cell_data:\n",
    "        print('//////////enter if cell_data in run_prediction/////')\n",
    "        print('cell_data=', cell_data)\n",
    "        pos = (pos + 1) % len(cell_data)  # iterate through entire list one at a time\n",
    "        print('pos=(pos + 1) % len(cell_data)=', pos)\n",
    "        sample = cell_data[pos]\n",
    "        print('sample = cell_data[pos]=', sample)\n",
    "    predict(sample)\n",
    "\n",
    "def predict(celldata):\n",
    "    print('/////////////enter def predict/////////////////')      \n",
    "    \"\"\"\n",
    "    This is the method that's to perform prediction based on a model\n",
    "    For now it just returns dummy data\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    ai_model = load_model_parameter()\n",
    "    print('ai_model.summary()=', ai_model)\n",
    "    print('celldata:', celldata)\n",
    "    ret = predict_unseen_data(ai_model, celldata)\n",
    "    print('ret=predict_unseen_data(ai_model, celldata)=', ret)\n",
    "    print('celldata:', celldata)\n",
    "    print('Classification', ret)\n",
    "    print('////prediction doneee///////')\n",
    "    return ret\n",
    "\n",
    "def load_model_parameter():\n",
    "    print('/////////////enter def load_model_parameters////////////////')\n",
    "    PATH = 'model.pth'\n",
    "    print('PATH = model.pth=', PATH)      \n",
    "    cwd = os.getcwd()\n",
    "    print('cwd=os.getcwd=', cwd)\n",
    "    print('os.listdir(cwd)=', os.listdir(cwd))\n",
    "    if not os.path.exists(PATH):\n",
    "        print('///enter if not os.path.exists(PATH):////')\n",
    "        with ZipFile('C:/Users/Mohammadreza/Desktop/My Class/Proj-DC/My Works/Scheduling/xApp/mr7-main/mr/model.zip', 'r') as zip:\n",
    "            zip.printdir()\n",
    "            zip.extractall()\n",
    "    #input_dim = 10\n",
    "    input_dim = 9\n",
    "    hidden_dim = 256\n",
    "    layer_dim = 3\n",
    "    output_dim = 2\n",
    "    device = \"cpu\"\n",
    "    #model = LSTMClassifier(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "    #print('model=LSTClassifier=', model)\n",
    "    \n",
    "    model = LSTMClassifier()\n",
    "    print('model=LSTClassifier=', model.summary())\n",
    "    \n",
    "    model.save(cwd)\n",
    "    \n",
    "    model = tf.keras.models.load_model(cwd)\n",
    "    \n",
    "#     print(\"Model's state_dict:\")\n",
    "#     for param_tensor in model.state_dict():\n",
    "#         print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "#     # model = model.to(device)\n",
    "#     torch.save(model.state_dict(), PATH)\n",
    "    \n",
    "#     model.load_state_dict(torch.load(PATH))\n",
    "#     model.eval()\n",
    "#     print('model.eval()=', model)      \n",
    "    # print(model)\n",
    "    return model\n",
    "\n",
    "def predict_unseen_data(model, unseen_data):\n",
    "    print('/////////////////enter def predict_unseen_data///////////////////')\n",
    "    print('unseen_data=', unseen_data)\n",
    "    #print('unseen_data[measTimeStampRf]=', unseen_data['measTimeStampRf'])\n",
    "    np_data = np.asarray(unseen_data, dtype=np.float32)\n",
    "    print('np_data=', np_data)\n",
    "    print('newaxis=', newaxis)\n",
    "    X_grouped = np_data[newaxis, newaxis, :]\n",
    "    print('X_grouped = np_data[newaxis, newaxis, :]=',  X_grouped)\n",
    "    print('X_grouped.transpose(0, 2, 1)=', X_grouped.transpose(0, 2, 1))\n",
    "    \n",
    "#     print('torch.tensor(X_grouped.transpose(0, 2, 1))=', torch.tensor(X_grouped.transpose(0, 2, 1)))\n",
    "#     X_grouped = torch.tensor(X_grouped.transpose(0, 2, 1)).float()\n",
    "#     print('X_grouped=', X_grouped)\n",
    "#     y_fake = torch.tensor([0] * len(X_grouped)).long()\n",
    "#     print('y_fake=', y_fake)\n",
    "    \n",
    "    print('X_grouped.transpose=', X_grouped.transpose)\n",
    "    X_grouped = X_grouped.transpose(0,2,1)\n",
    "    print('X_grouped.transpose(0,2,1)=', X_grouped)\n",
    "    X_grouped = tf.convert_to_tensor(X_grouped, dtype=tf.float32)\n",
    "    print('X_grouped=', X_grouped)\n",
    "    y_fake = tf.convert_to_tensor([0] * len(X_grouped), dtype=tf.int64)\n",
    "    print('y_fake=', y_fake)\n",
    "    \n",
    "#     tensor_test = TensorDataset(X_grouped, y_fake)\n",
    "#     print('tensor_test= TensorDataset(X_grouped, y_fake)=', tensor_test)\n",
    "    \n",
    "    tensor_test = tf.data.Dataset.from_tensors((X_grouped, y_fake))\n",
    "    print('tensor_test= TensorDataset(X_grouped, y_fake)=', tensor_test)\n",
    "    \n",
    "#     test_dl = DataLoader(tensor_test, batch_size=1, shuffle=False)\n",
    "#     print('test_dl=', test_dl)    \n",
    "    \n",
    "    test_dl = tensor_test.batch(1)\n",
    "    print('test_dl=', test_dl) \n",
    "    \n",
    "    model.fit(tensor_test, epochs=20, verbose=1)\n",
    "    \n",
    "    ret = []\n",
    "    for batch, _ in test_dl:\n",
    "        print('///enter for loop in predict unseen data////')\n",
    "        #batch = batch.permute(0, 2, 1)\n",
    "        print('batch=', batch)\n",
    "        batch = batch[0]\n",
    "        print('batch = batch[0]=', batch)\n",
    "        #batch = tf.transpose(batch, perm=[0,2,1])\n",
    "        #batch = tf.transpose(batch)\n",
    "        #print('batch = tf.transpose(batch, (0,2,1))=', batch)\n",
    "        \n",
    "        #batch = batch.transpose(0,2,1)\n",
    "        #print('batch = batch.transpose(0,2,1)=', batch)\n",
    "        #batch = tf.keras.layers.Permute((0,2,1), batch)\n",
    "        #print('batch= batch.permute(0, 2, 1)=', batch)\n",
    "        \n",
    "        out = model.predict(batch)\n",
    "        print('out=model(batch)=', out)\n",
    "        \n",
    "        y_hat = tf.nn.log_softmax(out)\n",
    "        print('y_hat = tf.nn.log_softmax(out)=', y_hat)\n",
    "        y_hat = tf.argmax(y_hat)\n",
    "        print('y_hat = tf.argmax(y_hat)=', y_hat)\n",
    "        #y_hat = F.log_softmax(out, dim=1).argmax(dim=1)\n",
    "        #print('y_hat= F.log_softmax(out, dim=1).argmax(dim=1)=', y_hat)\n",
    "        \n",
    "        y_hat = tf.get_static_value(y_hat, partial=False)\n",
    "        print('y_hat = tf.get_static_value(y_hat, partial=False)=', y_hat)\n",
    "        \n",
    "        ret += y_hat.tolist()\n",
    "        print('ret += y_hat.tolist()=', ret)\n",
    "    print('ret after for loop=', ret)\n",
    "    print('ret[0]', ret[0]) \n",
    "    if ret[0] == 0:\n",
    "        print('ret[0] == 0')  \n",
    "        return \"Normal\"\n",
    "    return \"Congestion\"\n",
    "\n",
    "def connectdb(action):\n",
    "    print('////////////////////enter def connectdb///////////////////')\n",
    "    # Create a connection to InfluxDB if thread=True, otherwise it will create a dummy data instance\n",
    "    global db\n",
    "    global cell_data\n",
    "    \n",
    "    print('//////enter else= populate.populate()////////////////')  \n",
    "    populate.populatedb(action)  # temporary method to populate db, it will be removed when data will be coming through KPIMON to influxDB\n",
    "\n",
    "    print('////came back from populate to connectdb.else:, db=DATABASE(CellData)///////')\n",
    "    db = DATABASE('CellData')\n",
    "    print('////came back from db.DATABASE-init to connectdb.else///////')\n",
    "    print('db =  DATABASE(celldata) =', db) \n",
    "    db.read_data(\"cellMeas\")\n",
    "    print('////came back from db.DATABASE-read-data to connectdb.else///////')\n",
    "    print('db.read_data(\"cellMeas\")=', db.read_data(\"cellMeas\"))\n",
    "    cell_data = db.data.values.tolist()  # needs to be updated in future when live feed will be coming through KPIMON to influxDB\n",
    "    print('cell_data = db.data.values.tolist()=', cell_data)\n",
    "    obs = [0] * 35\n",
    "    #print('obs=', obs)\n",
    "    obs[0:2] = cell_data[0][0:2]\n",
    "    #print('obs=', obs)\n",
    "    obs[2] = cell_data[0][12]\n",
    "    #print('obs=', obs)\n",
    "    obs[3] = cell_data[0][23]\n",
    "    #print('obs=', obs)\n",
    "    obs[4:10] = cell_data[0][31:37]\n",
    "    #print('obs=', obs)\n",
    "    obs[10:20] = cell_data[0][2:12]\n",
    "    #print('obs=', obs)\n",
    "    obs[20:29] = cell_data[0][13:23]\n",
    "    #print('obs=', obs)\n",
    "    obs[29:35] = cell_data[0][24:29]\n",
    "    print('obs=', obs)\n",
    "#     print('cell_data[0,1]=cell_data[0][0:2]=', cell_data[0][0:2])\n",
    "#     print('cell_data[2]=cell_data[0][12]=', cell_data[0][12])\n",
    "#     print('cell_data[3]=cell_data[0][23]=', cell_data[0][23])\n",
    "#     print('cell_data[10,...19]=cell_data[0][2:12]=', cell_data[0][2:12])\n",
    "#     print('cell_data[20,...29]=cell_data[0][13:29]=', cell_data[0][13:29])\n",
    "#     print('done = cell_data[0][30]=', cell_data[0][30])\n",
    "#     print('reward = cell_data[0][29]=', cell_data[0][29])\n",
    "#     print('cell_data[4,..,9]=cell_data[0][31:37]=', cell_data[0][31:37])\n",
    "    reward = cell_data[0][29]\n",
    "    done = cell_data[0][30]\n",
    "\n",
    "    #print('cell_data:, cell_data)\n",
    "    print('///////connectdb finished go to start//////')\n",
    "    return obs, reward, done\n",
    "#     if thread:\n",
    "#         print('///////////////enter if(thread) in connectdb///////////////////')  \n",
    "#         db = DUMMY()\n",
    "#         print('db =DUMMY()=', db)  \n",
    "#     else:\n",
    "#         print('//////enter else= populate.populate()////////////////')  \n",
    "#         populate.populatedb()  # temporary method to populate db, it will be removed when data will be coming through KPIMON to influxDB\n",
    "        \n",
    "#         print('////came back from populate to connectdb.else:, db=DATABASE(CellData)///////')\n",
    "#         db = DATABASE('CellData')\n",
    "#         print('////came back from db.DATABASE-init to connectdb.else///////')\n",
    "#         print('db =  DATABASE(celldata) =', db) \n",
    "#         db.read_data(\"cellMeas\")\n",
    "#         print('////came back from db.DATABASE-read-data to connectdb.else///////')\n",
    "#         print('db.read_data(\"cellMeas\")=', db.read_data(\"cellMeas\"))\n",
    "#         cell_data = db.data.values.tolist()  # needs to be updated in future when live feed will be coming through KPIMON to influxDB\n",
    "#         print('cell_data = db.data.values.tolist()=', cell_data)\n",
    "#         obs = [0] * 35\n",
    "#         print('obs=', obs)\n",
    "#         obs[0:2] = cell_data[0][0:2]\n",
    "#         print('obs=', obs)\n",
    "#         obs[2] = cell_data[0][12]\n",
    "#         print('obs=', obs)\n",
    "#         obs[3] = cell_data[0][23]\n",
    "#         print('obs=', obs)\n",
    "#         obs[4:10] = cell_data[0][31:37]\n",
    "#         print('obs=', obs)\n",
    "#         obs[10:20] = cell_data[0][2:12]\n",
    "#         print('obs=', obs)\n",
    "#         obs[20:29] = cell_data[0][13:23]\n",
    "#         print('obs=', obs)\n",
    "#         obs[29:35] = cell_data[0][24:29]\n",
    "#         print('obs=', obs)\n",
    "#         print('cell_data[0,1]=cell_data[0][0:2]=', cell_data[0][0:2])\n",
    "#         print('cell_data[2]=cell_data[0][12]=', cell_data[0][12])\n",
    "#         print('cell_data[3]=cell_data[0][23]=', cell_data[0][23])\n",
    "#         print('cell_data[10,...19]=cell_data[0][2:12]=', cell_data[0][2:12])\n",
    "#         print('cell_data[20,...29]=cell_data[0][13:29]=', cell_data[0][13:29])\n",
    "#         print('done = cell_data[0][30]=', cell_data[0][30])\n",
    "#         print('reward = cell_data[0][29]=', cell_data[0][29])\n",
    "#         print('cell_data[4,..,9]=cell_data[0][31:37]=', cell_data[0][31:37])\n",
    "#         reward = cell_data[0][29]\n",
    "#         done = cell_data[0][30]\n",
    "        \n",
    "#         #print('cell_data:, cell_data)\n",
    "#         print('///////connectdb finished go to start//////')\n",
    "#         return obs, reward, done\n",
    "\n",
    "def start(thread=False):\n",
    " \n",
    "    print('////////////////entered Starrrrrrrrrrrt///////////////////')\n",
    "    \"\"\"\n",
    "    This is a convenience function that allows this xapp to run in Docker\n",
    "    for \"real\" (no thread, real SDL), but also easily modified for unit testing\n",
    "    (e.g., use_fake_sdl). The defaults for this function are for the Dockerized xapp.\n",
    "    \"\"\"\n",
    "    global xapp, ai_model\n",
    "    #fake_sdl = getenv(\"USE_FAKE_SDL\", None)\n",
    "    #xapp = Xapp(entrypoint=entry, rmr_port=4560, use_fake_sdl=False)\n",
    "    \n",
    "    #connectdb(thread)\n",
    "    #print('///////come back from connectdb////////')\n",
    "    #ai_model = load_model_parameter()\n",
    "    #print('ai_model.summary in start=', ai_model)\n",
    "    \n",
    "    use_fake_sdl=False\n",
    "    rmr_port=4560\n",
    "    #xapp= entry(self)\n",
    "    #xapp.run()\n",
    "    entry()\n",
    "    \n",
    "    #fake_sdl = getenv(\"USE_FAKE_SDL\", None)\n",
    "    #xapp = Xapp(entrypoint=entry, rmr_port=4560, use_fake_sdl=False)\n",
    "    #print('xapp = Xapp(entrypoint=entry, rmr_port=4560, use_fake_sdl=fake_sdl)=', xapp)\n",
    "    #connectdb(thread)\n",
    "    #ai_model = load_model_parameter()\n",
    "    #print('ai_model.summary=', ai_model)\n",
    "    \n",
    "    #xapp.run()\n",
    "\n",
    "\n",
    "def stop():\n",
    "    print('/////////////enter def stop//////////////////')      \n",
    "    \"\"\"\n",
    "    can only be called if thread=True when started\n",
    "    \"\"\"\n",
    "    xapp.stop()\n",
    "\n",
    "\n",
    "def get_stats():\n",
    "    print('//////////////////enter def get_stats()////////////////////')\n",
    "    \"\"\"\n",
    "    hacky for now, will evolve\n",
    "    \"\"\"\n",
    "    print('DefCalled:rmr_xapp.def_hand_called=', rmr_xapp.def_hand_called)\n",
    "    print('SteeringRequests:rmr_xapp.traffic_steering_requests=', rmr_xapp.traffic_steering_requests) \n",
    "    return {\"DefCalled\": rmr_xapp.def_hand_called,\n",
    "            \"SteeringRequests\": rmr_xapp.traffic_steering_requests}\n",
    "\n",
    "# class LSTMClassifier(nn.Module):\n",
    "#     print('/////////////////enter class LSTClassifier////////////////////')      \n",
    "#     def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "#         print('///////enter def __init__ in LST//////////////////')  \n",
    "#         super().__init__()\n",
    "#         self.hidden_dim = hidden_dim\n",
    "#         print('self.hidden_dim=', self.hidden_dim)\n",
    "#         self.layer_dim = layer_dim\n",
    "#         print('self.layer_dim=', self.layer_dim)\n",
    "#         self.rnn = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "#         self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "#         self.batch_size = None\n",
    "#         self.hidden = None\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         print('////////enter def forward in LST//////////////////') \n",
    "#         h0, c0 = self.init_hidden(x)\n",
    "#         print('h0, c0 = self.init_hidden(x)', h0)\n",
    "#         print('h0, c0 = self.init_hidden(x)', c0)\n",
    "#         out, (hn, cn) = self.rnn(x, (h0, c0))\n",
    "#         out = self.fc(out[:, -1, :])\n",
    "#         print('out = self.fc(out[:, -1, :])=', out)\n",
    "#         return out\n",
    "\n",
    "#     def init_hidden(self, x):\n",
    "#         print('/////////enter def init_hidden in LST//////////////////')   \n",
    "#         h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)\n",
    "#         print('h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)', h0)\n",
    "#         c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)\n",
    "#         print('c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)', c0)\n",
    "#         return [t for t in (h0, c0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe44928",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('////////////////entered Starrrrrrrrrrrt///////////////////')\n",
    "\"\"\"\n",
    "This is a convenience function that allows this xapp to run in Docker\n",
    "for \"real\" (no thread, real SDL), but also easily modified for unit testing\n",
    "(e.g., use_fake_sdl). The defaults for this function are for the Dockerized xapp.\n",
    "\"\"\"\n",
    "thread = False\n",
    "global xapp, ai_model\n",
    "#fake_sdl = getenv(\"USE_FAKE_SDL\", None)\n",
    "#xapp = Xapp(entrypoint=entry, rmr_port=4560, use_fake_sdl=False)\n",
    "\n",
    "#obs, reward, done = connectdb(thread)\n",
    "#print('obs after connectdb =', obs)\n",
    "#print('reward after connectdb =', reward)\n",
    "#print('done after connectdb =', done)\n",
    "#print('///////come back from connectdb////////')\n",
    "\n",
    "\n",
    "use_fake_sdl=False\n",
    "rmr_port=4560\n",
    "#xapp= entry(self)\n",
    "#xapp.run()\n",
    "entry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5dc724",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bff6ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
